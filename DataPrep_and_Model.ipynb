{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59079311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import App.dataset as dataset\n",
    "import App.visualisation as visualisation\n",
    "from App.config import WIDTH, HEIGHT, NUMBER_OF_CHANNELS, Z_SCALE, RANDOM_MIN_VALUE, RANDOM_MAX_VALUE, BATCH_SIZE, BOTTLENECK_NUMBER_OF_FEATURE, INPUT_SHAPE\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f74098",
   "metadata": {},
   "source": [
    "# Creation du Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85210aee",
   "metadata": {},
   "source": [
    "### 1. Créer un jeu de données en appliquant les prép-traitements nécessaires à l'AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3523c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le dossier contenant les fichiers LiDAR\n",
    "folder_path = \"Data/dataset/sequences/00/velodyne/\"\n",
    "# Créer le dataset\n",
    "dataset_lidar_00 = dataset.create_bev_dataset_from_folder(folder_path, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad9f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le dossier contenant les fichiers LiDAR\n",
    "folder_path = \"Data/dataset/sequences/00/velodyne/\"\n",
    "# Créer le dataset\n",
    "dataset_lidar_01 = dataset.create_bev_dataset_from_folder(folder_path, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40818a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le dossier contenant les fichiers LiDAR\n",
    "folder_path = \"Data/dataset/sequences/01/velodyne/\"\n",
    "# Créer le dataset\n",
    "validation_dataset = dataset.create_bev_dataset_from_folder(folder_path, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ed907a",
   "metadata": {},
   "source": [
    "### 2. Visualisation de quelques exemples de données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1fcc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation avec une image\n",
    "\n",
    "lidar_data = dataset.read_kitti_lidar(\"Data/dataset/sequences/00/velodyne/000000.bin\")\n",
    "bev = dataset.lidar_to_bev(lidar_data, bev_height=HEIGHT, bev_width=WIDTH, z_scale=Z_SCALE)\n",
    "# Remplacer les zéros par des valeurs aléatoires\n",
    "bev_with_random = dataset.replace_zeros_with_random(bev, min_value=RANDOM_MIN_VALUE, max_value=RANDOM_MAX_VALUE)\n",
    "\n",
    "# Afficher les canaux BEV\n",
    "visualisation.show_bev(bev_with_random, channel=0, title=\"BEV - Intensité\")\n",
    "visualisation.show_bev(bev_with_random, channel=1, title=\"BEV - Hauteur\")\n",
    "visualisation.show_bev(bev_with_random, channel=2, title=\"BEV - Densité\")\n",
    "\n",
    "# Afficher les nuages de points LiDAR\n",
    "visualisation.lidar_point_clouds = [lidar_data]\n",
    "visualisation.display_lidar_point_cloud(\"Data/dataset/sequences/00/velodyne/000000.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e93ef1",
   "metadata": {},
   "source": [
    "# Création Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb54efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import App.autoencoder as autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa5530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle AutoEncoder BEV\n",
    "bev_autoencoder = autoencoder.create_bev_autoencoder(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    bottleneck=BOTTLENECK_NUMBER_OF_FEATURE\n",
    ")\n",
    "# Affichage du résumé du modèle AutoEncoder\n",
    "bev_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf31341d",
   "metadata": {},
   "source": [
    "# Apprentissage Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcbfa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the AutoEncoder model\n",
    "def train_bev_autoencoder( \n",
    "    model,\n",
    "    dataset,\n",
    "    epochs=10,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=0.0001,\n",
    "    save_path='bev_autoencoder.h5'\n",
    "):\n",
    "    \"\"\"\n",
    "    Entraîne le modèle AutoEncoder BEV.\n",
    "    \n",
    "    :param model: Modèle AutoEncoder à entraîner.\n",
    "    :param dataset: Dataset TensorFlow pour l'entraînement.\n",
    "    :param epochs: Nombre d'époques pour l'entraînement.\n",
    "    :param batch_size: Taille du batch pour l'entraînement.\n",
    "    :param learning_rate: Taux d'apprentissage pour l'optimiseur.\n",
    "    :param save_path: Chemin pour enregistrer le modèle entraîné.\n",
    "    \"\"\"\n",
    "    \n",
    "    # COmpile the model with absolute squared error loss and Adam optimizer\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mae'] \n",
    "    )\n",
    "    \n",
    "    history = model.fit(dataset, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "    # Enregistrement du modèle\n",
    "    model.save(save_path)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6a2857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle AutoEncoder BEV\n",
    "history = train_bev_autoencoder(\n",
    "    model=bev_autoencoder,\n",
    "    dataset=dataset_lidar_00,\n",
    "    epochs=10,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=0.001,\n",
    "    save_path='bev_autoencoder.h5'\n",
    ")\n",
    "# Affichage de l'historique d'entraînement\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ffa009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle AutoEncoder BEV\n",
    "history = train_bev_autoencoder(\n",
    "    model=bev_autoencoder,\n",
    "    dataset=dataset_lidar_01,  # Utilisation du dataset créé précédemment\n",
    "    epochs=10,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=0.001,\n",
    "    save_path='bev_autoencoder.h5'\n",
    ")\n",
    "# Affichage de l'historique d'entraînement\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9178590d",
   "metadata": {},
   "source": [
    "# Validation de l'auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d0d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation du modèle AutoEncoder BEV\n",
    "def validate_bev_autoencoder(model, dataset, num_samples=5):\n",
    "    \"\"\"\n",
    "    Valide le modèle AutoEncoder BEV en affichant des exemples d'entrées et de sorties.\n",
    "    \n",
    "    :param model: Modèle AutoEncoder à valider.\n",
    "    :param dataset: Dataset TensorFlow pour la validation.\n",
    "    :param num_samples: Nombre d'échantillons à afficher.\n",
    "    \"\"\"\n",
    "    for i, (input_data, target_data) in enumerate(dataset.take(num_samples)):\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "        reconstructed = model.predict(input_data)\n",
    "        \n",
    "        # Affichage des entrées et des reconstructions\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(\"Input BEV\")\n",
    "        plt.imshow(input_data[0])\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(\"Reconstructed BEV\")\n",
    "        plt.imshow(reconstructed[0])\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a2d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation du modèle AutoEncoder BEV\n",
    "validate_bev_autoencoder(\n",
    "    model=bev_autoencoder,\n",
    "    dataset=validation_dataset,\n",
    "    num_samples=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e4d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul la courbe de validation\n",
    "def plot_validation_curve(model, dataset, num_samples=5):\n",
    "    \"\"\"\n",
    "    Affiche la courbe de validation du modèle AutoEncoder BEV.\n",
    "    \n",
    "    :param model: Modèle AutoEncoder à valider.\n",
    "    :param dataset: Dataset TensorFlow pour la validation.\n",
    "    :param num_samples: Nombre d'échantillons à afficher.\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    for input_data, target_data in dataset.take(num_samples):\n",
    "        reconstructed = model.predict(input_data)\n",
    "        loss = tf.keras.losses.MeanSquaredError()\n",
    "        loss = loss(target_data, reconstructed)\n",
    "        losses.append(tf.reduce_mean(loss).numpy())\n",
    "    \n",
    "    plt.plot(losses)\n",
    "    plt.title('Validation Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.show()\n",
    "\n",
    "# Affichage de la courbe de validation\n",
    "plot_validation_curve(\n",
    "    model=bev_autoencoder,\n",
    "    dataset=validation_dataset,\n",
    "    num_samples=5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
